{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 19:58:01.869783: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-08 19:58:02.237903: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-08 19:58:02.239245: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-08 19:58:03.636917: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from qkeras import *\n",
    "from qkeras import QActivation\n",
    "from qkeras import QDense, QConv2DBatchnorm\n",
    "import hls4ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path to Vitis HLS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vitis HLS directory should be specified to use hls4ml with the high-level synthesis tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH Xilinx Virtual Machine\n",
    "\n",
    "os.environ['PATH'] = '/mnt/d/Xilinx/Vitis_HLS/2022.2/bin:' + os.environ['PATH']\n",
    "os.environ['PATH'] = '/mnt/d/Xilinx/Vitis/2022.2/bin:' + os.environ['PATH']\n",
    "os.environ['PATH'] = '/mnt/d/Xilinx/Vivado/2022.2/bin:' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fisica\\Desktop\\valentina\\Guatemala\\labs\\lab5\\Lab5_HLS4ML\\neuralEnv\\Lib\\site-packages\\keras\\initializers\\initializers.py:120: UserWarning: The initializer LecunUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"studentQ_CNN_MLP\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1 (QConv2D)             (None, 26, 26, 16)        160       \n",
      "                                                                 \n",
      " conv1_act (QActivation)     (None, 26, 26, 16)        0         \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 13, 13, 16)        0         \n",
      "                                                                 \n",
      " conv2 (QConv2D)             (None, 11, 11, 32)        4640      \n",
      "                                                                 \n",
      " conv2_act (QActivation)     (None, 11, 11, 32)        0         \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 5, 5, 32)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 800)               0         \n",
      "                                                                 \n",
      " fc1 (QDense)                (None, 64)                51264     \n",
      "                                                                 \n",
      " relu1 (QActivation)         (None, 64)                0         \n",
      "                                                                 \n",
      " fc2 (QDense)                (None, 32)                2080      \n",
      "                                                                 \n",
      " relu2 (QActivation)         (None, 32)                0         \n",
      "                                                                 \n",
      " drop1 (Dropout)             (None, 32)                0         \n",
      "                                                                 \n",
      " output (QDense)             (None, 10)                330       \n",
      "                                                                 \n",
      " outputActivation (Activatio  (None, 10)               0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,474\n",
      "Trainable params: 58,474\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load keras model \n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "co = {}\n",
    "_add_supported_quantized_objects(co)\n",
    "model = load_model('../models/studentModelMnistCNN.h5', custom_objects=co)\n",
    "model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hls4ml integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hls4ml** is a Python package developed for converting machine learning (ML) models into HLS (High-Level Synthesis) projects, enabling deployment of ML-based inference on hardware like FPGAs. More details can be found at [hls4ml documentation](https://fastmachinelearning.org/hls4ml/).\n",
    "\n",
    "The user can control several options related to the model, including:\n",
    "\n",
    "- **Precision:** Define the precision of the calculations in your model (e.g., fixed-point or floating-point representation).\n",
    "\n",
    "- **Dataflow/Resource Reuse:** Control the level of parallelism or streaming in model implementations, with varying degrees of pipelining.\n",
    "\n",
    "- **Quantization Aware Training:** Achieve optimized performance at low precision by using tools like QKeras. Models trained with QKeras benefit automatically from hls4ml's parsing of QKeras models during inference.\n",
    "\n",
    "An HLS configuration should be created using the function `hls4ml.utils.config_from_keras_model(kerasModel, granularity)`, where kerasModel is the pre-trained model you want to implement on an FPGA, and granularity determines the configuration level. The two possible values for granularity are:\n",
    "\n",
    "- 'model': The same configuration applies to the entire model (e.g., all layers use 16-bit fixed-point precision).\n",
    "\n",
    "- 'name': Layer-specific configurations can be applied (e.g., the input layer can be defined in 8-bit fixed-point precision, while the second layer is set to 16-bit fixed-point precision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: inputLayer, layer type: InputLayer, input shapes: [[None, 28, 28, 1]], output shape: [None, 28, 28, 1]\n",
      "Layer name: conv1, layer type: QConv2D, input shapes: [[None, 28, 28, 1]], output shape: [None, 26, 26, 16]\n",
      "Layer name: conv1_act, layer type: Activation, input shapes: [[None, 26, 26, 16]], output shape: [None, 26, 26, 16]\n",
      "Layer name: pool1, layer type: MaxPooling2D, input shapes: [[None, 26, 26, 16]], output shape: [None, 13, 13, 16]\n",
      "Layer name: conv2, layer type: QConv2D, input shapes: [[None, 13, 13, 16]], output shape: [None, 11, 11, 32]\n",
      "Layer name: conv2_act, layer type: Activation, input shapes: [[None, 11, 11, 32]], output shape: [None, 11, 11, 32]\n",
      "Layer name: pool2, layer type: MaxPooling2D, input shapes: [[None, 11, 11, 32]], output shape: [None, 5, 5, 32]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 5, 5, 32]], output shape: [None, 800]\n",
      "Layer name: fc1, layer type: QDense, input shapes: [[None, 800]], output shape: [None, 64]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 64]], output shape: [None, 64]\n",
      "Layer name: fc2, layer type: QDense, input shapes: [[None, 64]], output shape: [None, 32]\n",
      "Layer name: relu2, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: output, layer type: QDense, input shapes: [[None, 32]], output shape: [None, 10]\n",
      "Layer name: outputActivation, layer type: Softmax, input shapes: [[None, 10]], output shape: [None, 10]\n",
      "-----------------------------------\n",
      "Model\n",
      "  Precision\n",
      "    default:         fixed<16,6>\n",
      "  ReuseFactor:       1\n",
      "  Strategy:          Latency\n",
      "  BramFactor:        1000000000\n",
      "  TraceOutput:       False\n",
      "LayerName\n",
      "  inputLayer\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  conv1\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "      weight:        fixed<8,5,TRN,WRAP,0>\n",
      "      bias:          fixed<8,5,TRN,WRAP,0>\n",
      "  conv1_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  conv1_act\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<8,1,RND_CONV,SAT,0>\n",
      "  pool1\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  conv2\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "      weight:        fixed<8,5,TRN,WRAP,0>\n",
      "      bias:          fixed<8,5,TRN,WRAP,0>\n",
      "  conv2_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  conv2_act\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<8,1,RND_CONV,SAT,0>\n",
      "  pool2\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  flatten\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  fc1\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "      weight:        fixed<8,5,TRN,WRAP,0>\n",
      "      bias:          fixed<8,5,TRN,WRAP,0>\n",
      "  fc1_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  relu1\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<8,1,RND_CONV,SAT,0>\n",
      "  fc2\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "      weight:        fixed<8,5,TRN,WRAP,0>\n",
      "      bias:          fixed<8,5,TRN,WRAP,0>\n",
      "  fc2_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  relu2\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<8,1,RND_CONV,SAT,0>\n",
      "  output\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "      weight:        fixed<16,7,TRN,WRAP,0>\n",
      "      bias:          fixed<16,7,TRN,WRAP,0>\n",
      "  output_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  outputActivation\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hls_config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "\n",
    "\n",
    "from src import plotting\n",
    "\n",
    "print(\"-----------------------------------\")\n",
    "plotting.print_dict(hls_config)\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: inputLayer, layer type: InputLayer, input shapes: [[None, 28, 28, 1]], output shape: [None, 28, 28, 1]\n",
      "Layer name: conv1, layer type: QConv2D, input shapes: [[None, 28, 28, 1]], output shape: [None, 26, 26, 16]\n",
      "Layer name: conv1_act, layer type: Activation, input shapes: [[None, 26, 26, 16]], output shape: [None, 26, 26, 16]\n",
      "Layer name: pool1, layer type: MaxPooling2D, input shapes: [[None, 26, 26, 16]], output shape: [None, 13, 13, 16]\n",
      "Layer name: conv2, layer type: QConv2D, input shapes: [[None, 13, 13, 16]], output shape: [None, 11, 11, 32]\n",
      "Layer name: conv2_act, layer type: Activation, input shapes: [[None, 11, 11, 32]], output shape: [None, 11, 11, 32]\n",
      "Layer name: pool2, layer type: MaxPooling2D, input shapes: [[None, 11, 11, 32]], output shape: [None, 5, 5, 32]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 5, 5, 32]], output shape: [None, 800]\n",
      "Layer name: fc1, layer type: QDense, input shapes: [[None, 800]], output shape: [None, 64]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 64]], output shape: [None, 64]\n",
      "Layer name: fc2, layer type: QDense, input shapes: [[None, 64]], output shape: [None, 32]\n",
      "Layer name: relu2, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: output, layer type: QDense, input shapes: [[None, 32]], output shape: [None, 10]\n",
      "Layer name: outputActivation, layer type: Softmax, input shapes: [[None, 10]], output shape: [None, 10]\n"
     ]
    }
   ],
   "source": [
    "hls_config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Layer in hls_config['LayerName'].keys():\n",
    "    hls_config['LayerName'][Layer]['Strategy'] = 'Latency'\n",
    "    hls_config['LayerName'][Layer]['ReuseFactor'] = 1\n",
    "    hls_config['LayerName'][Layer]['Precision'] = 'ap_fixed<8,4>'\n",
    "\n",
    "hls_config['LayerName']['outputActivation']['Strategy'] = 'Stable'\n",
    "hls_config['Model']['Precision'] = 'ap_fixed<16,6>'\n",
    "\n",
    "hls_config['LayerName']['inputLayer']['Precision'] = 'ap_fixed<16, 6>'   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hls4ml with Vitis HLS as backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: inputLayer, layer type: InputLayer, input shapes: [[None, 28, 28, 1]], output shape: [None, 28, 28, 1]\n",
      "Layer name: conv1, layer type: QConv2D, input shapes: [[None, 28, 28, 1]], output shape: [None, 26, 26, 16]\n",
      "Layer name: conv1_act, layer type: Activation, input shapes: [[None, 26, 26, 16]], output shape: [None, 26, 26, 16]\n",
      "Layer name: pool1, layer type: MaxPooling2D, input shapes: [[None, 26, 26, 16]], output shape: [None, 13, 13, 16]\n",
      "Layer name: conv2, layer type: QConv2D, input shapes: [[None, 13, 13, 16]], output shape: [None, 11, 11, 32]\n",
      "Layer name: conv2_act, layer type: Activation, input shapes: [[None, 11, 11, 32]], output shape: [None, 11, 11, 32]\n",
      "Layer name: pool2, layer type: MaxPooling2D, input shapes: [[None, 11, 11, 32]], output shape: [None, 5, 5, 32]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 5, 5, 32]], output shape: [None, 800]\n",
      "Layer name: fc1, layer type: QDense, input shapes: [[None, 800]], output shape: [None, 64]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 64]], output shape: [None, 64]\n",
      "Layer name: fc2, layer type: QDense, input shapes: [[None, 64]], output shape: [None, 32]\n",
      "Layer name: relu2, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: output, layer type: QDense, input shapes: [[None, 32]], output shape: [None, 10]\n",
      "Layer name: outputActivation, layer type: Softmax, input shapes: [[None, 10]], output shape: [None, 10]\n",
      "Creating HLS model\n",
      "Writing HLS project\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "\".\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n",
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Failed to compile project \"myproject\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPart\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxc7z020clg400-1\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# PYNQ-Z1 or Zedboard: xc7z020clg484-1  \u001b[39;00m\n\u001b[0;32m     13\u001b[0m hls_model \u001b[38;5;241m=\u001b[39m hls4ml\u001b[38;5;241m.\u001b[39mconverters\u001b[38;5;241m.\u001b[39mkeras_to_hls(cfg)\n\u001b[1;32m---> 15\u001b[0m \u001b[43mhls_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fisica\\Desktop\\valentina\\Guatemala\\labs\\lab5\\Lab5_HLS4ML\\neuralEnv\\Lib\\site-packages\\hls4ml\\model\\graph.py:695\u001b[0m, in \u001b[0;36mModelGraph.compile\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compile the generated project and link the library into current environment.\u001b[39;00m\n\u001b[0;32m    691\u001b[0m \n\u001b[0;32m    692\u001b[0m \u001b[38;5;124;03mUsers should call this function if they want to use `predict` functionality for simulation.\u001b[39;00m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite()\n\u001b[1;32m--> 695\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fisica\\Desktop\\valentina\\Guatemala\\labs\\lab5\\Lab5_HLS4ML\\neuralEnv\\Lib\\site-packages\\hls4ml\\model\\graph.py:698\u001b[0m, in \u001b[0;36mModelGraph._compile\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_compile\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 698\u001b[0m     lib_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_top_function_lib \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    700\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m platform\u001b[38;5;241m.\u001b[39msystem() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinux\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\fisica\\Desktop\\valentina\\Guatemala\\labs\\lab5\\Lab5_HLS4ML\\neuralEnv\\Lib\\site-packages\\hls4ml\\backends\\fpga\\fpga_backend.py:174\u001b[0m, in \u001b[0;36mFPGABackend.compile\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret_val\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28mprint\u001b[39m(ret_val\u001b[38;5;241m.\u001b[39mstdout)\n\u001b[1;32m--> 174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to compile project \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget_project_name()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    175\u001b[0m lib_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/firmware/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.so\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    176\u001b[0m     model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget_output_dir(), model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget_project_name(), model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget_config_value(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStamp\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    177\u001b[0m )\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lib_name\n",
      "\u001b[1;31mException\u001b[0m: Failed to compile project \"myproject\""
     ]
    }
   ],
   "source": [
    "# Create configuration for Vitis HLS as backend.\n",
    "cfg = hls4ml.converters.create_config(backend='Vitis')\n",
    "\n",
    "# HLSConfig correspond to the configuration created in hls_config \n",
    "cfg['HLSConfig']  = hls_config\n",
    "# Model to be converted\n",
    "cfg['KerasModel'] = model\n",
    "# Folder where the HLS project will be created\n",
    "cfg['OutputDir']  = 'vitis_mnistCNN/'\n",
    "# FPGA part \n",
    "cfg['Part'] = 'xc7z020clg400-1'  # PYNQ-Z1 or Zedboard: xc7z020clg484-1  \n",
    "  \n",
    "hls_model = hls4ml.converters.keras_to_hls(cfg)\n",
    "\n",
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Usar en terminal el sigueinte comando\n",
    "# $env:PATH += \";D:\\Xilinx\\Vitis_HLS\\2022.2\\bin\"\n",
    "# vitis_hls -version\n",
    "# cd .\\pythonModel\\hlsPrj\\\n",
    "# vitis_hls -f .\\build_prj.tcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSynthesis report not found.\n",
      "Vivado synthesis report not found.\n",
      "Cosim report not found.\n",
      "Timing report not found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will perform the synthesis of the HLS project, showing the main results (latency and resource usage) once the process is completed. \n",
    "\n",
    "hls_model.build(csim=False, export=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this stage is complete, you can return to the wiki to continue with the next steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
